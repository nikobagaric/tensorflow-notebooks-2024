{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Long-Short Term Memory Stock Predictor\n",
        "\n",
        "2024, Niko Bagaric TF practice project"
      ],
      "metadata": {
        "id": "OxKKB7qaeKLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Functions"
      ],
      "metadata": {
        "id": "qPVLg8azeid4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alpha_vantage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59hz15aCfRqe",
        "outputId": "b8776bcf-b598-40e5-fcbb-d689ab4294c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: alpha_vantage in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from alpha_vantage) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from alpha_vantage) (2.31.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->alpha_vantage) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->alpha_vantage) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->alpha_vantage) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->alpha_vantage) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->alpha_vantage) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->alpha_vantage) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->alpha_vantage) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->alpha_vantage) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->alpha_vantage) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->alpha_vantage) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from alpha_vantage.timeseries import TimeSeries"
      ],
      "metadata": {
        "id": "puMp24bmePTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getStockData(ticker_symbol, ts):\n",
        "  data, metadata = ts.get_daily(symbol=ticker_symbol, outputsize='full')\n",
        "\n",
        "  data['SMA_50'] = data['4. close'].rolling(window=50).mean()\n",
        "  data['SMA_200'] = data['4. close'].rolling(window=200).mean()\n",
        "\n",
        "  data.dropna(inplace=True)\n",
        "\n",
        "  features = data[['4. close', 'SMA_50', 'SMA_200']]\n",
        "\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "  X, y = [], []\n",
        "  for i in range(len(scaled_features) - 60):\n",
        "    X.append(scaled_features[i:i + 60])\n",
        "    y.append(scaled_features[i + 60, 0])\n",
        "\n",
        "  X, y = np.array(X), np.array(y)\n",
        "\n",
        "  return X, y\n",
        "\n",
        "def makeEvaluationPlot(X1, y1):\n",
        "  # Evaluate the model\n",
        "  loss = model.evaluate(X1, y1)\n",
        "\n",
        "  # Make predictions\n",
        "  predictions = model.predict(X1)\n",
        "  predictions = scaler.inverse_transform(np.concatenate((predictions, X1[:, 0, 1:]), axis=1))[:, 0]\n",
        "  y1 = scaler.inverse_transform(np.concatenate((y1.reshape(-1, 1), X1[:, 0, 1:]), axis=1))[:, 0]\n",
        "\n",
        "  # Plot the results\n",
        "  plt.figure(figsize=(14, 5))\n",
        "  plt.plot(y1, color='blue', label='Actual Stock Price')\n",
        "  plt.plot(predictions, color='red', label='Predicted Stock Price')\n",
        "  plt.title('Stock Price Prediction using LSTM')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Stock Price')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eHSYjVRGlQs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Grabbing\n",
        "\n",
        "The data is grabbed from [here](https://www.alphavantage.co/)"
      ],
      "metadata": {
        "id": "XL4fCtZCevvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define API key and TS\n",
        "api_key = '5GRU22E0YWFC30NK'\n",
        "ts = TimeSeries(key=api_key, output_format='pandas')"
      ],
      "metadata": {
        "id": "v3xgOskzfuPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ticker symbol (apple)\n",
        "ticker_symbol = 'AAPL'"
      ],
      "metadata": {
        "id": "HkzxHI9sezgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = getStockData(ticker_symbol=ticker_symbol,\n",
        "                    ts=ts)"
      ],
      "metadata": {
        "id": "DTi5D6UOow31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "8FMjSalnoSir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model A-01"
      ],
      "metadata": {
        "id": "rrvfjl2NiomS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "rwr58s53lJSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRDgyaVhiBmn",
        "outputId": "24bb13a1-dc12-4074-a335-667f4807121f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "148/148 [==============================] - 11s 36ms/step - loss: 0.0065 - val_loss: 7.6342e-04\n",
            "Epoch 2/100\n",
            "148/148 [==============================] - 4s 26ms/step - loss: 0.0031 - val_loss: 6.7238e-04\n",
            "Epoch 3/100\n",
            "148/148 [==============================] - 4s 26ms/step - loss: 0.0026 - val_loss: 1.8729e-04\n",
            "Epoch 4/100\n",
            "148/148 [==============================] - 3s 20ms/step - loss: 0.0022 - val_loss: 1.1015e-04\n",
            "Epoch 5/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0022 - val_loss: 1.1517e-04\n",
            "Epoch 6/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 5.4863e-05\n",
            "Epoch 7/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0017 - val_loss: 1.8664e-04\n",
            "Epoch 8/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0017 - val_loss: 5.6797e-05\n",
            "Epoch 9/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.0015 - val_loss: 5.1811e-05\n",
            "Epoch 10/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 5.5842e-05\n",
            "Epoch 11/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 1.4314e-04\n",
            "Epoch 12/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 4.9996e-05\n",
            "Epoch 13/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 2.4725e-04\n",
            "Epoch 14/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 0.0012 - val_loss: 6.5166e-05\n",
            "Epoch 15/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 2.4794e-04\n",
            "Epoch 16/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 3.8577e-05\n",
            "Epoch 17/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0010 - val_loss: 4.5570e-05\n",
            "Epoch 18/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.0010 - val_loss: 1.2659e-04\n",
            "Epoch 19/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 9.5113e-04 - val_loss: 5.5038e-05\n",
            "Epoch 20/100\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.0010 - val_loss: 2.7736e-05\n",
            "Epoch 21/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 9.1542e-04 - val_loss: 6.3543e-05\n",
            "Epoch 22/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 9.0918e-04 - val_loss: 2.7491e-04\n",
            "Epoch 23/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 8.4908e-04 - val_loss: 5.8342e-05\n",
            "Epoch 24/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 9.0989e-04 - val_loss: 3.4904e-05\n",
            "Epoch 25/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 8.9202e-04 - val_loss: 2.2460e-05\n",
            "Epoch 26/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 8.5113e-04 - val_loss: 2.5634e-05\n",
            "Epoch 27/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 8.5352e-04 - val_loss: 3.6805e-05\n",
            "Epoch 28/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 8.7265e-04 - val_loss: 7.8169e-05\n",
            "Epoch 29/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 7.9208e-04 - val_loss: 9.6981e-05\n",
            "Epoch 30/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 8.3979e-04 - val_loss: 4.1319e-05\n",
            "Epoch 31/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.4220e-04 - val_loss: 5.4296e-05\n",
            "Epoch 32/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 8.2138e-04 - val_loss: 3.2444e-05\n",
            "Epoch 33/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 7.9282e-04 - val_loss: 4.9910e-05\n",
            "Epoch 34/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 7.5513e-04 - val_loss: 1.8407e-05\n",
            "Epoch 35/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.2292e-04 - val_loss: 5.8629e-05\n",
            "Epoch 36/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.4012e-04 - val_loss: 1.9678e-05\n",
            "Epoch 37/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.6475e-04 - val_loss: 3.5102e-05\n",
            "Epoch 38/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 7.8589e-04 - val_loss: 2.4482e-04\n",
            "Epoch 39/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 7.2190e-04 - val_loss: 6.1354e-05\n",
            "Epoch 40/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 7.5866e-04 - val_loss: 5.9576e-05\n",
            "Epoch 41/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.6136e-04 - val_loss: 1.3425e-04\n",
            "Epoch 42/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 7.5803e-04 - val_loss: 1.6897e-05\n",
            "Epoch 43/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.9397e-04 - val_loss: 5.9840e-05\n",
            "Epoch 44/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.3175e-04 - val_loss: 1.3034e-04\n",
            "Epoch 45/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 6.4326e-04 - val_loss: 8.7560e-05\n",
            "Epoch 46/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 7.2646e-04 - val_loss: 1.9176e-05\n",
            "Epoch 47/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 7.0082e-04 - val_loss: 3.0387e-05\n",
            "Epoch 48/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 6.9031e-04 - val_loss: 9.2062e-05\n",
            "Epoch 49/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 7.1092e-04 - val_loss: 4.3218e-05\n",
            "Epoch 50/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 6.7997e-04 - val_loss: 1.5589e-05\n",
            "Epoch 51/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 6.8860e-04 - val_loss: 5.5232e-05\n",
            "Epoch 52/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 7.7055e-04 - val_loss: 2.0758e-05\n",
            "Epoch 53/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 6.8344e-04 - val_loss: 7.4989e-05\n",
            "Epoch 54/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6751e-04 - val_loss: 4.2239e-04\n",
            "Epoch 55/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.6012e-04 - val_loss: 8.5126e-05\n",
            "Epoch 56/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6743e-04 - val_loss: 3.4584e-05\n",
            "Epoch 57/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 6.9744e-04 - val_loss: 9.7577e-05\n",
            "Epoch 58/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.9459e-04 - val_loss: 1.0072e-04\n",
            "Epoch 59/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 7.0815e-04 - val_loss: 9.1692e-05\n",
            "Epoch 60/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.8558e-04 - val_loss: 6.3695e-05\n",
            "Epoch 61/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 6.9798e-04 - val_loss: 2.0902e-05\n",
            "Epoch 62/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.8065e-04 - val_loss: 1.3436e-04\n",
            "Epoch 63/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.5842e-04 - val_loss: 8.9186e-04\n",
            "Epoch 64/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 7.0807e-04 - val_loss: 3.0049e-05\n",
            "Epoch 65/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 6.9040e-04 - val_loss: 1.6247e-05\n",
            "Epoch 66/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 6.7648e-04 - val_loss: 2.6721e-05\n",
            "Epoch 67/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.3199e-04 - val_loss: 4.2847e-04\n",
            "Epoch 68/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6268e-04 - val_loss: 1.9644e-05\n",
            "Epoch 69/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.8730e-04 - val_loss: 3.1411e-04\n",
            "Epoch 70/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.2778e-04 - val_loss: 1.8903e-04\n",
            "Epoch 71/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6648e-04 - val_loss: 2.1538e-05\n",
            "Epoch 72/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 6.0243e-04 - val_loss: 2.1811e-05\n",
            "Epoch 73/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 6.2600e-04 - val_loss: 2.1070e-04\n",
            "Epoch 74/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.8894e-04 - val_loss: 1.6456e-05\n",
            "Epoch 75/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.1891e-04 - val_loss: 6.7066e-05\n",
            "Epoch 76/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 6.3571e-04 - val_loss: 9.9590e-05\n",
            "Epoch 77/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.4147e-04 - val_loss: 1.8973e-05\n",
            "Epoch 78/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 7.6564e-04 - val_loss: 6.0501e-05\n",
            "Epoch 79/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 6.6755e-04 - val_loss: 1.7890e-04\n",
            "Epoch 80/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.5895e-04 - val_loss: 1.6487e-05\n",
            "Epoch 81/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6261e-04 - val_loss: 1.0208e-04\n",
            "Epoch 82/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.7707e-04 - val_loss: 7.2515e-05\n",
            "Epoch 83/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.8123e-04 - val_loss: 2.8424e-05\n",
            "Epoch 84/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.1386e-04 - val_loss: 2.4810e-05\n",
            "Epoch 85/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 6.3807e-04 - val_loss: 2.7937e-04\n",
            "Epoch 86/100\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 6.4666e-04 - val_loss: 7.7179e-05\n",
            "Epoch 87/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.5582e-04 - val_loss: 5.9060e-05\n",
            "Epoch 88/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.7262e-04 - val_loss: 3.5443e-05\n",
            "Epoch 89/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6828e-04 - val_loss: 2.3214e-05\n",
            "Epoch 90/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.9547e-04 - val_loss: 3.3290e-05\n",
            "Epoch 91/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.0884e-04 - val_loss: 3.2217e-05\n",
            "Epoch 92/100\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 6.4693e-04 - val_loss: 1.6713e-05\n",
            "Epoch 93/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6685e-04 - val_loss: 8.1904e-05\n",
            "Epoch 94/100\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 6.4961e-04 - val_loss: 1.7534e-05\n",
            "Epoch 95/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.2347e-04 - val_loss: 5.4557e-05\n",
            "Epoch 96/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.9026e-04 - val_loss: 1.8369e-05\n",
            "Epoch 97/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.6512e-04 - val_loss: 3.1440e-05\n",
            "Epoch 98/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 6.4426e-04 - val_loss: 1.8053e-05\n",
            "Epoch 99/100\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 6.4274e-04 - val_loss: 1.5673e-05\n",
            "Epoch 100/100\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 6.3715e-04 - val_loss: 2.5178e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "makeEvaluationPlot(X1=X_test,\n",
        "                   y1=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDsUGpzqiCAv",
        "outputId": "ed9a7168-abf0-49f4-9f3f-32e4289e088e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 0s 8ms/step - loss: 2.5178e-05\n",
            "37/37 [==============================] - 2s 6ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scaler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c21400aff5bc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m makeEvaluationPlot(X1=X_test,\n\u001b[0m\u001b[1;32m      2\u001b[0m                    y1=y_test)\n",
            "\u001b[0;32m<ipython-input-11-194a17bf268e>\u001b[0m in \u001b[0;36mmakeEvaluationPlot\u001b[0;34m(X1, y1)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on different dataset (different stock)\n",
        "\n",
        "Testing on different stock"
      ],
      "metadata": {
        "id": "XqyBcoEllMVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_symbol_nvidia = 'NVDA'\n",
        "\n",
        "X1, y1 = getStockData(ticker_symbol=ticker_symbol_nvidia,\n",
        "                      ts=ts)"
      ],
      "metadata": {
        "id": "ntmAIJr1lOrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate on a big set\n",
        "\n",
        "makeEvaluationPlot(X1=X1,\n",
        "                   y1=y1)"
      ],
      "metadata": {
        "id": "wu1AD-pYqN2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_symbol_msft = 'MSFT'\n",
        "\n",
        "X2, y2 = getStockData(ticker_symbol=ticker_symbol_msft,\n",
        "                      ts=ts)"
      ],
      "metadata": {
        "id": "y3j7qEVpaS9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('')"
      ],
      "metadata": {
        "id": "eu435miDavBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}